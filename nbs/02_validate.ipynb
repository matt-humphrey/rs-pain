{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- Add validation for metadata -> should be a separate heading (validate alignment across ALL datasets: should be identical)\n",
    "- Update Dataset class so it doesn't have to take prefix or usecols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rich\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandera.polars as pa\n",
    "from pandera.typing import DataFrame, Series\n",
    "from typing import Any\n",
    "import pyreadstat\n",
    "from functools import partial\n",
    "\n",
    "from pain.read import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metadata import METADATA\n",
    "data_dir = Path(\"../data/raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define expected data structure for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PN17 = partial(pa.Field, isin=(-99, 0, 1), coerce=True)\n",
    "PN25 = partial(pa.Field, isin=(-88, -99, 0, 1), coerce=True)\n",
    "PN34 = partial(pa.Field, isin=(-88, -99, 0, 1), coerce=True)\n",
    "PN35 = partial(pa.Field, isin=(-88, -99, 0, 1), coerce=True)\n",
    "PN36 = partial(pa.Field, isin=(-88, -99, 0, 1), coerce=True)\n",
    "\n",
    "# Only applicable for G217_PQ and G217_SQ\n",
    "PN9 = partial(pa.Field, isin=(-88, -99, 0, 1), coerce=True)\n",
    "PN38 = partial(pa.Field, isin=(-88, -99, 0, 1), coerce=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G214_PQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G214_PQ = Dataset(\"G214_PQ.sav\", data_dir)\n",
    "df, meta = G214_PQ.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df\n",
    "    .select(\n",
    "        pl.col(\"G214_PQ_PN17\").replace({9: -99}),\n",
    "        pl.col(\"G214_PQ_PN25\").replace({8: -88, 9: -99}),\n",
    "        pl.col(\"G214_PQ_PN34\").replace({8: -88, 9: -99}),\n",
    "        pl.col(\"G214_PQ_PN35\").replace({8: -88, 9: -99}),\n",
    "        pl.col(\"G214_PQ_PN36\").replace({8: -88, 9: -99})\n",
    "    )\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G214PQSchema(pa.DataFrameModel):\n",
    "    G214_PQ_PN17: Series[int] = PN17()\n",
    "    G214_PQ_PN25: Series[int] = PN25()\n",
    "    G214_PQ_PN34: Series[int] = PN34()\n",
    "    G214_PQ_PN35: Series[int] = PN35()\n",
    "    G214_PQ_PN36: Series[int] = PN36()\n",
    "\n",
    "    @pa.dataframe_check\n",
    "    def check_for_na(cls, data: pa.PolarsData) -> pl.LazyFrame:\n",
    "        \"\"\"Verify when PN17 is 0, all subsequent values are -88 (ie. if no back pain, other variables should be N/A).\"\"\"\n",
    "        s = pl.col(\"G214_PQ_PN25\", \"G214_PQ_PN34\", \"G214_PQ_PN35\", \"G214_PQ_PN36\")\n",
    "        return data.lazyframe.filter(pl.col(\"G214_PQ_PN17\") == 0).select(s == -88)\n",
    "    \n",
    "    @pa.dataframe_check\n",
    "    def check_for_na2(cls, data: pa.PolarsData) -> pl.LazyFrame:\n",
    "        \"\"\"\n",
    "        Verify the reverse of the above, where if any subsequent variables has a value of -88, PN17 should be 0.\n",
    "        Except PN35, where there are valid values of -88 when PN17 is 0\n",
    "        \"\"\"\n",
    "        f = ((pl.col(\"G214_PQ_PN25\") == -88) |\n",
    "             (pl.col(\"G214_PQ_PN34\") == -88) |\n",
    "             (pl.col(\"G214_PQ_PN36\") == -88))\n",
    "        return data.lazyframe.filter(f).select(pl.col(\"G214_PQ_PN17\") == 0)\n",
    "\n",
    "try:\n",
    "    G214PQSchema.validate(df, lazy=True)\n",
    "except pa.errors.SchemaErrors as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Metadata Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One sensible approach would be to take a collection of Metadata and transform it so rather than having each variable defined independently, in isolation, that data is converted to be in the same format as the current metadata structure of the dataset (ie. Parameters as parents, variables as children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_meta = convert_metadata_list_to_dict(METADATA, p=\"G214_PQ_\")\n",
    "m = merge_dictionaries([new_meta, meta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, ValidationError, field_validator\n",
    "\n",
    "# General validation class for metadata in nested dictionary format\n",
    "class MetaDict(BaseModel):\n",
    "    label: dict[str, str|None] # TODO: replace None with empty string? Valid error - should have label?\n",
    "    field_values: dict[str, dict[int, str]]\n",
    "    field_type: dict[str, str] # TODO: Add validator to ensure values are one of [\"Numeric\", \"String\", \"Date\"]\n",
    "    field_width: dict[str, int]\n",
    "    decimals: dict[str, int]\n",
    "    variable_type: dict[str, str]\n",
    "\n",
    "    # TODO: validator fail because they're trying to read individual elements, not the larger dict\n",
    "    # Can I create BaseModels for each parameter? Hard without knowing and specifying the individual variables\n",
    "\n",
    "    # @field_validator('variable_type', mode='before')\n",
    "    # @classmethod\n",
    "    # def lowercase(cls, value: str) -> str:\n",
    "    #     return value.lower()\n",
    "\n",
    "    # @field_validator('field_type', mode='before')\n",
    "    # @classmethod\n",
    "    # def check_field_type(cls, value: str) -> str:\n",
    "    #     if value in [\"Numeric\", \"String\", \"Date\"]:\n",
    "    #         return value\n",
    "    #     else:\n",
    "    #         raise ValueError(f\"{value} not one of 'Numeric', 'String' or 'Date'.\")\n",
    "\n",
    "    # TODO: check that the keys of each dict are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def munge_keys(m: dict[str, dict[str, Any]]) -> dict[str, dict[str, Any]]:\n",
    "    \"\"\"Munge outer keys of dictionary for use with Pydantic.\"\"\"\n",
    "    return {k.lower().replace(\" \", \"_\"): v for k, v in m.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mMetaDict\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mlabel\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'G214_PQ_PN17'\u001b[0m: \u001b[32m'Ever had back pain'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN25'\u001b[0m: \u001b[32m'Sought professional advice/treatment'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN34'\u001b[0m: \u001b[32m'Took medication to relieve pain'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN35'\u001b[0m: \u001b[32m'Missed work due to pain'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN36'\u001b[0m: \u001b[32m'Pain interfered with normal activities'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN9'\u001b[0m: \u001b[32m'Ever had neck/shoulder pain'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN38'\u001b[0m: \u001b[32m'Ever had low back pain'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mfield_values\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'G214_PQ_PN17'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1;36m-99\u001b[0m: \u001b[32m'Missing'\u001b[0m, \u001b[1;36m0\u001b[0m: \u001b[32m'No'\u001b[0m, \u001b[1;36m1\u001b[0m: \u001b[32m'Yes'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN25'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1;36m-88\u001b[0m: \u001b[32m'N/A'\u001b[0m, \u001b[1;36m-99\u001b[0m: \u001b[32m'Missing'\u001b[0m, \u001b[1;36m0\u001b[0m: \u001b[32m'No'\u001b[0m, \u001b[1;36m1\u001b[0m: \u001b[32m'Yes'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN34'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1;36m-88\u001b[0m: \u001b[32m'N/A'\u001b[0m, \u001b[1;36m-99\u001b[0m: \u001b[32m'Missing'\u001b[0m, \u001b[1;36m0\u001b[0m: \u001b[32m'No'\u001b[0m, \u001b[1;36m1\u001b[0m: \u001b[32m'Yes'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN35'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1;36m-88\u001b[0m: \u001b[32m'N/A'\u001b[0m, \u001b[1;36m-99\u001b[0m: \u001b[32m'Missing'\u001b[0m, \u001b[1;36m0\u001b[0m: \u001b[32m'No'\u001b[0m, \u001b[1;36m1\u001b[0m: \u001b[32m'Yes'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN36'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1;36m-88\u001b[0m: \u001b[32m'N/A'\u001b[0m, \u001b[1;36m-99\u001b[0m: \u001b[32m'Missing'\u001b[0m, \u001b[1;36m0\u001b[0m: \u001b[32m'No'\u001b[0m, \u001b[1;36m1\u001b[0m: \u001b[32m'Yes'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN9'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1;36m-99\u001b[0m: \u001b[32m'Missing'\u001b[0m, \u001b[1;36m0\u001b[0m: \u001b[32m'No'\u001b[0m, \u001b[1;36m1\u001b[0m: \u001b[32m'Yes'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN38'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1;36m-99\u001b[0m: \u001b[32m'Missing'\u001b[0m, \u001b[1;36m0\u001b[0m: \u001b[32m'No'\u001b[0m, \u001b[1;36m1\u001b[0m: \u001b[32m'Yes'\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mfield_type\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'G214_PQ_PN17'\u001b[0m: \u001b[32m'Numeric'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN25'\u001b[0m: \u001b[32m'Numeric'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN34'\u001b[0m: \u001b[32m'Numeric'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN35'\u001b[0m: \u001b[32m'Numeric'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN36'\u001b[0m: \u001b[32m'Numeric'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN9'\u001b[0m: \u001b[32m'Numeric'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN38'\u001b[0m: \u001b[32m'Numeric'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mfield_width\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'G214_PQ_PN17'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m'G214_PQ_PN25'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m'G214_PQ_PN34'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m'G214_PQ_PN35'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m'G214_PQ_PN36'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m'G214_PQ_PN9'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m'G214_PQ_PN38'\u001b[0m: \u001b[1;36m3\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mdecimals\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'G214_PQ_PN17'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'G214_PQ_PN25'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'G214_PQ_PN34'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'G214_PQ_PN35'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'G214_PQ_PN36'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'G214_PQ_PN9'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'G214_PQ_PN38'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mvariable_type\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'G214_PQ_PN17'\u001b[0m: \u001b[32m'nominal'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN25'\u001b[0m: \u001b[32m'nominal'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN34'\u001b[0m: \u001b[32m'nominal'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN35'\u001b[0m: \u001b[32m'nominal'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN36'\u001b[0m: \u001b[32m'nominal'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN9'\u001b[0m: \u001b[32m'nominal'\u001b[0m,\n",
       "        \u001b[32m'G214_PQ_PN38'\u001b[0m: \u001b[32m'nominal'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MetaDict(**munge_keys(new_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Munge variable names to suit Pydantic\n",
    "# TODO: convert this into an actual reusable function\n",
    "m2 = munge_keys(m)\n",
    "try:\n",
    "    MetaDict(**m2)\n",
    "except ValidationError as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Label(BaseModel):\n",
    "    G214_PQ_PN17: str = 'Ever had back pain'\n",
    "    G214_PQ_PN25: str = 'Sought professional advice/treatment'\n",
    "    G214_PQ_PN34: str = 'Took medication to relieve pain'\n",
    "    G214_PQ_PN35: str = 'Missed work due to pain'\n",
    "    G214_PQ_PN36: str = 'Pain interfered with normal activities'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Meta(BaseModel):\n",
    "    label: Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mMeta\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mlabel\u001b[0m=\u001b[1;35mLabel\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mG214_PQ_PN17\u001b[0m=\u001b[32m'Ever had back pain'\u001b[0m,\n",
       "        \u001b[33mG214_PQ_PN25\u001b[0m=\u001b[32m'Sought professional advice/treatment'\u001b[0m,\n",
       "        \u001b[33mG214_PQ_PN34\u001b[0m=\u001b[32m'Took medication to relieve pain'\u001b[0m,\n",
       "        \u001b[33mG214_PQ_PN35\u001b[0m=\u001b[32m'Missed work due to pain'\u001b[0m,\n",
       "        \u001b[33mG214_PQ_PN36\u001b[0m=\u001b[32m'Pain interfered with normal activities'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Meta(**munge_keys(new_meta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## G214_SQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G214_SQ = Dataset(\"G214_SQ.sav\", data_dir)\n",
    "df, _ = G214_SQ.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df\n",
    "    .with_columns(\n",
    "        pl.col(\"G214_SQ_PN17\").replace({9: -99}),\n",
    "        pl.col(\"G214_SQ_PN25\").replace({8: -88, 9: -99}),\n",
    "        pl.col(\"G214_SQ_PN34\").replace({8: -88, 9: -99}),\n",
    "        pl.col(\"G214_SQ_PN35\").replace({8: -88, 9: -99}),\n",
    "        pl.col(\"G214_SQ_PN36\").replace({8: -88, 9: -99}),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSchema_G214_SQ(pa.DataFrameModel):\n",
    "    G214_SQ_PN17: Series[int] = PN17(nullable=True)\n",
    "    G214_SQ_PN25: Series[int] = PN25(nullable=True)\n",
    "    G214_SQ_PN34: Series[int] = PN34(nullable=True)\n",
    "    G214_SQ_PN35: Series[int] = PN35(nullable=True)\n",
    "    G214_SQ_PN36: Series[int] = PN36(nullable=True)\n",
    "\n",
    "    @pa.dataframe_check\n",
    "    def check_for_na(cls, data: pa.PolarsData) -> pl.LazyFrame:\n",
    "        \"\"\"Verify when PN17 is 0, all subsequent values are -88 (ie. if no back pain, other variables should be N/A).\"\"\"\n",
    "        s = pl.col(\"G214_SQ_PN25\", \"G214_SQ_PN34\", \"G214_SQ_PN35\", \"G214_SQ_PN36\")\n",
    "        return data.lazyframe.filter(pl.col(\"G214_SQ_PN17\") == 0).select(s == -88)\n",
    "    \n",
    "    @pa.dataframe_check\n",
    "    def check_for_na2(cls, data: pa.PolarsData) -> pl.LazyFrame:\n",
    "        \"\"\"\n",
    "        Verify the reverse of the above, where if any subsequent variables has a value of -88, PN17 should be 0.\n",
    "        Except PN35, where there are valid values of -88 when PN17 is 0\n",
    "        \"\"\"\n",
    "        f = ((pl.col(\"G214_SQ_PN25\") == -88) |\n",
    "             (pl.col(\"G214_SQ_PN34\") == -88) |\n",
    "             (pl.col(\"G214_SQ_PN36\") == -88))\n",
    "        return data.lazyframe.filter(f).select(pl.col(\"G214_SQ_PN17\") == 0)\n",
    "\n",
    "try:\n",
    "    DataSchema_G214_SQ.validate(df.collect(), lazy=True)\n",
    "except pa.errors.SchemaErrors as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G217_PQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G217_PQ = Dataset(\"G217_PQ.sav\", data_dir)\n",
    "df, _ = G217_PQ.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df\n",
    "    .select(\n",
    "        pl.col(\"G217_PQ_PN17\").replace({9: -99}),\n",
    "        pl.col(\"G217_PQ_PN9\").replace({7: -99, 9: -99}),\n",
    "        pl.col(\"G217_PQ_PN38\").replace({7: -99, 9: -99}),\n",
    "        pl.col(\"G217_PQ_PN25\").replace({7: -99, 9: -99}),\n",
    "        pl.col(\"G217_PQ_PN34\").replace({7: -99, 9: -99}),\n",
    "        pl.col(\"G217_PQ_PN35\").replace({7: -99, 9: -99}),\n",
    "        pl.col(\"G217_PQ_PN36\").replace({7: -99, 9: -99})\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G217PQSchema(pa.DataFrameModel):\n",
    "    G217_PQ_PN17: Series[int] = PN17()\n",
    "    G217_PQ_PN9: Series[int] = PN9()\n",
    "    G217_PQ_PN38: Series[int] = PN38()\n",
    "    G217_PQ_PN25: Series[int] = PN25()\n",
    "    G217_PQ_PN34: Series[int] = PN34()\n",
    "    G217_PQ_PN35: Series[int] = PN35()\n",
    "    G217_PQ_PN36: Series[int] = PN36()\n",
    "\n",
    "try:\n",
    "    df = G217PQSchema.validate(df, lazy=True)\n",
    "except pa.errors.SchemaErrors as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G217_SQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G217_SQ = Dataset(\"G217_SQ.sav\", data_dir)\n",
    "df, _ = G217_SQ.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df\n",
    "    .select(\n",
    "        pl.col(\"G217_SQ_PN17\").replace({9: -99}),\n",
    "        pl.col(\"G217_SQ_PN9\").replace({9: -99}),\n",
    "        pl.col(\"G217_SQ_PN38\").replace({9: -99}),\n",
    "        pl.col(\"G217_SQ_PN25\").replace({9: -99}),\n",
    "        pl.col(\"G217_SQ_PN34\").replace({9: -99}),\n",
    "        pl.col(\"G217_SQ_PN35\").replace({9: -99}),\n",
    "        pl.col(\"G217_SQ_PN36\").replace({9: -99})\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G217SQDataSchema(pa.DataFrameModel):\n",
    "    G217_SQ_PN17: Series[int] = PN17()\n",
    "    G217_SQ_PN9: Series[int] = PN9()\n",
    "    G217_SQ_PN38: Series[int] = PN38()\n",
    "    G217_SQ_PN25: Series[int] = PN25()\n",
    "    G217_SQ_PN34: Series[int] = PN34()\n",
    "    G217_SQ_PN35: Series[int] = PN35()\n",
    "    G217_SQ_PN36: Series[int] = PN36()\n",
    "\n",
    "try:\n",
    "    df = G217SQDataSchema.validate(df, lazy=True)\n",
    "except pa.errors.SchemaErrors as err:\n",
    "    print(err)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
